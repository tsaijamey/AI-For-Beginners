# Knowledge Representation and Expert Systems

![Summary of Symbolic AI content](../../sketchnotes/ai-symbolic.png)

> Sketchnote by [Tomomi Imura](https://twitter.com/girlie_mac)

**手绘图的解释说明**(由GPT与GPT-Vision生成)
<div style="background-color: #d8b2d1; border: 1px solid #a379a8; padding: 10px; margin: 10px;">
这张草图式风格的图片描述了人工智能中的符号AI（Symbolic AI），也被称作GOFAI（Good Old-Fashioned Artificial Intelligence），以及它的主要概念和组成部分。图片中包含了以下内容和结构：

- **知识表示（Knowledge Representation）**：这包括了不同的数据组织形式，如DIKW金字塔（数据-信息-知识-智慧），以及用于注解互联网资源的本体论和语义网的描述逻辑（Description Logics），和资源描述框架（RDF）。

- **本体论与语义网（Ontologies & Semantic Web）**：表示知识在互联网上的结构化，例如通过使用DBpedia和WikiData等工具来查询和管理知识。

- **自顶向下的方法（Top-down Approach）**：强调人类知识和推理的应用，这是符号AI中的一个主要方法，它依赖于网络和层次化的知识表示方式，以及决策制定。

- **专家系统（Expert Systems）**：一种知识驱动的AI系统，它使用人类的长期记忆和神经系统的推理模式来解决问题。包括使用逻辑推理，如正向和反向推理，并且通常是手工创建的本体论。

- **决策制定（Decision Making）**：符号AI使用知识基础来进行决策制定，例如，判断一个动物是不是肉食性动物，可以基于其具有锋利的牙齿和爪子。

整体上，这张图片可能是用于描述一个关于符号AI的课程结构，其中涉及知识表示、推理方法、专家系统和决策制定等关键AI概念。这些内容可能会被整合进入课程的不同模块或章节中，为学生提供一个关于符号AI的全面视角。
</div>

寻求人工智能基于对知识的搜索，以使机器能像人类一样理解世界。但你该如何做到这一点呢？

## [课前测验](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/102)

在人工智能的早期，采用自顶向下的方法（在上一课中讨论过）来创建智能系统是很流行的。这种方法的思想是将人类的知识提取到某种机器可读的形式中，然后使用它来自动解决问题。这种方法基于两个重要的思想：

* 知识表示
* 推理

## 知识表示

在符号AI中，**知识**是一个重要概念。区分知识、*信息*或*数据*是很重要的。例如，人们可以说书籍包含知识，因为人们可以通过学习书籍成为专家。然而，书籍实际上所包含的被称为*数据*，通过阅读书籍并将这些数据整合到我们的世界模型中，我们将这些数据转换为知识。

> ✅ **知识**是存在于我们头脑中的，代表我们对世界的理解。它是通过一个积极的**学习**过程获得的，这个过程将我们接收到的信息片段整合到我们积极的世界模型中。

我们通常不会严格定义知识，但我们会使用[DIKW金字塔](https://en.wikipedia.org/wiki/DIKW_pyramid)将其与其他相关概念对齐。它包含以下概念：

* **数据**是在物理媒介上表示的东西，例如书面文本或口头词语。数据独立于人类存在，并且可以在人与人之间传递。
* **信息**是我们在头脑中对数据的解释。例如，当我们听到*计算机*这个词时，我们对它是什么有一定的理解。
* **知识**是被整合到我们世界模型中的信息。例如，一旦我们了解了计算机是什么，我们就开始有一些关于它如何工作、它的成本以及它可以用来做什么的想法。这个相互关联的概念网络形成了我们的知识。
* **智慧**是我们对世界理解的又一个层次，它代表*元知识*，例如关于知识应当如何以及何时使用的一些概念。

<img src="../images/DIKW_Pyramid.png" width="30%"/>

*图片[来自维基百科](https://commons.wikimedia.org/w/index.php?curid=37705247)，作者Longlivetheux - 自己的作品，CC BY-SA 4.0*

因此，**知识表示**的问题是找到一种在计算机内以数据形式有效表示知识的方法，使其可以自动使用。这可以被看作是一个光谱：

![知识表示光谱](../images/knowledge-spectrum.png)

> 图片由[Dmitry Soshnikov](http://soshnikov.com)提供

* 在左边，有一些非常简单的知识表示类型，计算机可以有效使用。最简单的是算法性的，知识通过计算机程序来表示。然而，这并不是表示知识的最佳方式，因为它不够灵活。我们头脑中的知识往往是非算法性的。
* 在右边，有如自然文本这样的表示。它是最强大的，但不能用于自动推理。

> ✅ 花一分钟时间思考你是如何在头脑中表示知识并将其转化为笔记的。有没有一种特定的格式对你来说很有效，能帮助你记忆？

## 计算机知识表示分类

我们可以将不同的计算机知识表示方法分类如下：

* **网络表示法** 基于我们头脑中有一个相互关联的概念网络的事实。我们可以尝试在计算机内部以图的形式复现相同的网络——一个所谓的**语义网络**。

1. **对象-属性-值三元组** 或 **属性-值对**。由于图可以在计算机内部表示为节点和边的列表，我们可以通过一系列包含对象、属性和值的三元组来表示语义网络。例如，我们构建以下关于编程语言的三元组：

对象 | 属性 | 值
-------|-----------|------
Python | 是 | 无类型语言
Python | 发明者 | Guido van Rossum
Python | 块语法 | 缩进
无类型语言 | 没有 | 类型定义

> ✅ 思考三元组如何用于表示其他类型的知识。

2. **层次化表示法** 强调我们经常在头脑中创建对象的层次结构这一事实。例如，我们知道金丝雀是一种鸟，所有鸟都有翅膀。我们也有一些关于金丝雀通常是什么颜色，以及它们的飞行速度的想法。

   - **框架表示法** 基于将每个对象或对象类表示为包含**槽**的**框架**。槽可能有默认值、值限制，或存储的程序可以被调用以获取槽的值。所有框架形成一个层次结构，类似于面向对象编程语言中的对象层次结构。
   - **场景** 是一种特殊的框架，代表可以随时间展开的复杂情境。


**Python**

槽 | 值 | 默认值 | 区间 |
-----|-------|---------------|----------|
名称 | Python | | |
类型 | 无类型语言 | | |
变量大小写 | | 驼峰式 | |
程序长度 | | | 5-5000 行 |
块语法 | 缩进 | | |

3. **程序表示法** 是基于用一系列在特定条件出现时可以执行的动作来表示知识。
   - 产生规则是允许我们得出结论的if-then声明。例如，医生可能有一个规则说，**如果** 患者有高烧 **或者** 血液检测中C反应蛋白水平高，**那么** 他有炎症。一旦我们遇到其中一个条件，我们就可以对炎症做出结论，然后在进一步的推理中使用它。
   - 算法可以被认为是另一种形式的程序表示，尽管它们几乎从不直接用于基于知识的系统。

4. **逻辑** 最初由亚里士多德提出作为表示普遍人类知识的一种方式。
   - 谓词逻辑作为一种数学理论过于丰富，无法计算，因此通常使用它的某些子集，如Prolog中使用的霍恩子句。
   - 描述逻辑是一系列逻辑系统，用于表示和推理分布式知识表示（如*语义网*）中的对象层次结构。


## 专家系统

符号AI早期的成功之一是所谓的**专家系统**——设计用来在某些有限问题领域内扮演专家角色的计算机系统。它们基于从一个或多个人类专家那里提取的**知识库**，并包含了在其上执行某些推理的**推理引擎**。

![人类神经系统结构简图](../images/arch-human.png) | ![基于知识的系统结构](../images/arch-kbs.png)
---------------------------------------------|------------------------------------------------
人类神经系统的简化结构 | 基于知识系统的架构

专家系统构建得类似于人类的推理系统，包含**短期记忆**和**长期记忆**。类似地，在基于知识的系统中我们区分以下组件：

* **问题内存**：包含当前正在解决的问题的知识，例如病人的体温或血压，他是否有炎症等。这些知识也被称为**静态知识**，因为它包含了我们当前对问题所知的快照——所谓的*问题状态*。
* **知识库**：代表问题领域的长期知识。它是从人类专家那里手动提取的，并且从咨询到咨询不会改变。因为它允许我们从一个问题状态导航到另一个问题状态，所以它也被称为**动态知识**。
* **推理引擎**：协调整个在问题状态空间搜索的过程，必要时向用户提问。它还负责找到适用于每个状态的正确规则。

作为一个例子，让我们考虑以下基于物理特征确定动物的专家系统：

![AND-OR树](../images/AND-OR-Tree.png)

> 图片由[Dmitry Soshnikov](http://soshnikov.com)提供


这个图被称为**AND-OR树**，它是一组产生规则的图形表示。在从专家那里提取知识的开始阶段，绘制树是有用的。为了在计算机内部表示知识，使用规则更为方便：

```
如果动物吃肉
或者（
   动物有锋利的牙齿
   并且 动物有爪子
   并且 动物有向前看的眼睛
）
那么动物是食肉动物
```


你会注意到，规则左侧的每个条件和动作本质上都是对象-属性-值（OAV）三元组。**工作内存**包含与当前正在解决的问题相对应的一组OAV三元组。**规则引擎**寻找条件得到满足的规则并应用它们，向工作内存中添加另一个三元组。

> ✅ 在你喜欢的主题上编写你自己的AND-OR树！

### 正向推理与反向推理

上述过程称为**正向推理**。它从工作内存中关于问题的一些初始数据开始，然后执行以下推理循环：

1. 如果目标属性在工作内存中存在——停止并给出结果
2. 寻找所有当前条件得到满足的规则——获得**冲突集**规则。
3. 执行**冲突解决**——选择将在此步骤执行的一个规则。可能有不同的冲突解决策略：
   - 选择知识库中的第一个适用规则
   - 随机选择一个规则
   - 选择一个*更具体*的规则，即满足"左侧"（LHS）中大多数条件的规则
4. 应用所选规则并将新知识插入问题状态
5. 从步骤1重复。

然而，在某些情况下，我们可能希望从对问题一无所知开始，并询问将帮助我们得出结论的问题。例如，在进行医学诊断时，我们通常不会在开始诊断患者之前预先进行所有医学分析。我们宁愿在需要做出决定时进行分析。

这个过程可以使用**反向推理**来建模。它由**目标**驱动——我们正在寻找的属性值：

1. 选择所有能给我们提供目标值的规则（即目标在RHS（"右手边"）上）——冲突集
1. 如果这个属性没有规则，或者有一个规则说我们应该向用户询问值——询问它，否则：
1. 使用冲突解决策略选择我们将作为*假设*使用的一个规则——我们将尝试证明它
1. 递归重复规则LHS中所有属性的过程，试图证明它们为目标
1. 如果在任何时候过程失败——在第3步使用另一个规则。

> ✅ 在哪些情况下更适合使用正向推理？反向推理又如何？

### 实现专家系统

专家系统可以使用不同的工具来实现：

* 直接在某些高级编程语言中编程。这不是最好的主意，因为基于知识的系统的主要优势是知识与推理是分开的，而且潜在的问题领域专家应该能够在不理解推理过程细节的情况下编写规则
* 使用**专家系统外壳**，即一个专门设计用来通过使用某种知识表示语言填充知识的系统。

## ✍️ 练习：动物推理

查看[Animals.ipynb](https://github.com/microsoft/AI-For-Beginners/blob/main/lessons/2-Symbolic/Animals.ipynb)了解实现正向和反向推理专家系统的示例。

> **注意**：这个例子相当简单，只是给出了一个专家系统外观的想法。一旦你开始创建这样的系统，只有当你达到一定数量的规则时（大约200+），你才会注意到它的一些*智能*行为。在某个点上，规则变得太复杂，无法全部记住，这时你可能会开始想知道系统为何做出特定的决策。然而，基于知识的系统的一个重要特性是你总能*准确解释*任何决策是如何做出的。

## 本体论和语义网

在20世纪末，有一个倡议使用知识表示来注释互联网资源，使得可以找到与非常具体的查询相对应的资源。这一运动被称为**语义网**，它依赖于几个概念：

- 基于**[描述逻辑](https://en.wikipedia.org/wiki/Description_logic)**（DL）的特殊知识表示。它类似于框架知识表示，因为它构建了一个具有属性的对象层次结构，但它有正式的逻辑语义和推理。有一整套DL平衡了表达性和推理的算法复杂性。
- 分布式知识表示，所有概念都由全局URI标识符表示，使得创建跨互联网的知识层次结构成为可能。
- 用于知识描述的基于XML的语言家族：RDF（资源描述框架），RDFS（RDF模式），OWL（本体网络语言）。

语义网的核心概念是**本体论**。它指的是使用某种形式的知识表示对问题领域进行明确规范。最简单的本体论可能只是问题领域中对象的层次结构，但更复杂的本体论将包括可用于推理的规则。

在语义网中，所有的表示都基于三元组。每个对象和每个关系都通过URI唯一标识。例如，如果我们想声明这个AI课程是由Dmitry Soshnikov在2022年1月1日开发的事实——这里是我们可以使用的三元组：

<img src="../images/triplet.png" width="30%"/>

```
http://github.com/microsoft/ai-for-beginners http://www.example.com/terms/creation-date “Jan 13, 2007”
http://github.com/microsoft/ai-for-beginners http://purl.org/dc/elements/1.1/creator http://soshnikov.com
```


> ✅ 这里`http://www.example.com/terms/creation-date` 和 `http://purl.org/dc/elements/1.1/creator` 是一些众所周知且普遍接受的URI，用来表达*创建者*和*创建日期*的概念。

在更复杂的情况下，如果我们想定义一个创作者列表，我们可以使用RDF中定义的一些数据结构。

<img src="../images/triplet-complex.png" width="40%"/>

> 上面的图表由[Dmitry Soshnikov](http://soshnikov.com)提供

构建语义网的进展因搜索引擎和自然语言处理技术的成功而有所放缓，这些技术允许从文本中提取结构化数据。然而，在一些领域仍有显著努力维护本体和知识库。值得注意的几个项目包括：

* [WikiData](https://wikidata.org/) 是与维基百科相关联的机器可读知识库的集合。大部分数据是从维基百科*信息框*中挖掘出来的，信息框是维基百科页面内的结构化内容片段。你可以使用SPARQL（一个专门的语义网查询语言）查询wikidata，这里是一个显示人类中最流行的眼睛颜色的示例查询：

```sparql
#defaultView:BubbleChart
SELECT ?eyeColorLabel (COUNT(?human) AS ?count)
WHERE
{
  ?human wdt:P31 wd:Q5.       # 人类 实例属于 智人
  ?human wdt:P1340 ?eyeColor. # 人类 眼睛颜色 ?eyeColor
  SERVICE wikibase:label { bd:serviceParam wikibase:language "en". }
}
GROUP BY ?eyeColorLabel
```

* [DBpedia](https://www.dbpedia.org/) 是另一个类似于WikiData的努力。

> ✅ 如果你想尝试构建自己的本体论，或打开现有的本体论，有一个很棒的可视化本体论编辑器叫做[Protégé](https://protege.stanford.edu/)。下载它，或在线使用。

<img src="../images/protege.png" width="70%"/>

*Web Protégé编辑器打开罗曼诺夫家族本体论。截图由Dmitry Soshnikov提供*

## ✍️ 练习：一个家庭本体论


查看[FamilyOntology.ipynb](https://github.com/Ezana135/AI-For-Beginners/blob/main/lessons/2-Symbolic/FamilyOntology.ipynb)了解使用语义网技术推理家庭关系的示例。我们将采用以通用GEDCOM格式表示的家族树和家庭关系的本体论，为给定一组个体构建所有家庭关系的图表。

## 微软概念图

在大多数情况下，本体论是通过手工精心创建的。然而，也可以从非结构化数据中**挖掘**本体论，例如，从自然语言文本中。

微软研究院就进行了这样的尝试，结果是[微软概念图](https://blogs.microsoft.com/ai/microsoft-researchers-release-graph-that-helps-machines-conceptualize/?WT.mc_id=academic-77998-cacaste)。

它是一个大型实体集合，通过`是一种`继承关系聚集在一起。它允许回答像“微软是什么？”这样的问题——答案可能是“一家公司，可能性为0.87，和一个品牌，可能性为0.75”。

该图既可以作为REST API提供，也可以作为一个大型可下载的文本文件，列出所有实体对。


## ✍️ 练习：一个概念图

尝试[MSConceptGraph.ipynb](https://github.com/microsoft/AI-For-Beginners/blob/main/lessons/2-Symbolic/MSConceptGraph.ipynb)笔记本，看看我们如何使用微软概念图将新闻文章分为几个类别。

## 结论

如今，人工智能经常被视为*机器学习*或*神经网络*的同义词。然而，人类也展现出显式推理，这是当前神经网络未能处理的事物。在现实世界的项目中，显式推理仍然被用来执行需要解释的任务，或能够以可控方式修改系统行为的任务。

## 🚀 挑战

在本课程相关的家庭本体论笔记本中，有机会尝试其他家庭关系。尝试发现家族树中人与人之间的新联系。

## [课后测验](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/202)

## 复习与自学

在互联网上进行一些研究，发现人类试图量化和编码知识的领域。看看布鲁姆的分类法，回到历史上学习人类如何试图理解他们的世界。探索林奈创建生物分类法的工作，观察德米特里·门捷列夫如何创建一种描述和分组化学元素的方法。你还能找到哪些有趣的例子？

**作业**：[构建一个本体论](assignment.md)

