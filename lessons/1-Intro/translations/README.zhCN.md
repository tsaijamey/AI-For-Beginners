# AI入门简介

![Summary of Introduction of AI content in a doodle](../../sketchnotes/ai-intro.png)

> Sketchnote by [Tomomi Imura](https://twitter.com/girlie_mac)

**手绘图的解释说明**(由GPT与GPT-Vision生成)
<div style="background-color: #d8b2d1; border: 1px solid #a379a8; padding: 10px; margin: 10px;">
这张草图风格的图片是关于人工智能（AI）的一个介绍课程的结构概览。它包含了以下几个部分：

- **AI的分类**：这部分将AI分为了强AI（AGI，意指能够执行任何智能活动的AI）和弱AI（专注于特定任务的AI）。还涉及了机器学习（ML）和深度学习，后者是机器学习的一个子集。

- **方法论**：介绍了两种开发AI的方法：自顶向下（Top-down Approach）和自底向上（Bottom-up Approach）。自顶向下方法依赖于人类知识和推理，而自底向上方法则基于神经模型和训练数据。

- **历史里程碑**：从19世纪的查尔斯·巴贝奇（被称为“计算机之父”）开始，到1950年的图灵测试，这是艾伦·图灵提出的测试机器是否能够展现出智能的方法。

- **重要的AI里程碑**：这一部分列出了一系列历史上的里程碑，如1960年的ELIZA和Shakey，2000年的语义网，以及2000年代初的Roomba吸尘器和苹果公司的语音助手Siri。

- **近期研究**：突出了2015年的图像分类、2016年的卷积语音识别、2018年的自动机器翻译和2020年的图像字幕生成等领域的进展。

- **AI应用实例**：例如AlphaGo、智能手机和其他设备。

整体上，这张图片是对AI的一个通俗易懂的介绍，适用于初学者，展示了AI的不同方面、发展历程以及最近的一些研究进展。
</div>

## [课前小测验](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/101)

**人工智能**是一门令人兴奋的科学学科，它研究我们如何使计算机展现出智能行为，例如做那些人类擅长的事情。

最初，计算机是由[Charles Babbage](https://en.wikipedia.org/wiki/Charles_Babbage)发明的，用来按照一种明确定义的程序——一种算法来操作数字。即使是现代计算机，虽然比19世纪初提出的原型机要先进得多，但仍然遵循相同的受控计算思想。因此，如果我们知道为了达到目标需要执行的确切步骤序列，就有可能编程让计算机做某事。


![人脸年龄识别的图片](../images/dsh_age.png)

> 图片由 [Vickie Soshnikova](http://twitter.com/vickievalerie) 提供

> ✅ 从一个人的照片中定义其年龄是一个无法明确编程的任务，因为当我们这样做时，我们并不知道我们是如何在脑海中得出一个数字的。

---

然而，有一些任务我们并不明确知道如何解决。考虑一下从他/她的照片确定一个人的年龄的问题。我们不知何故学会了这样做，因为我们看过很多不同年龄的人的例子，但我们不能明确解释我们是如何做到的，也不能编程让计算机去做这件事。这正是**人工智能**（简称AI）感兴趣的任务类型。

✅ 考虑一些你可以让计算机卸载并从AI中受益的任务。考虑金融、医疗和艺术领域 - 这些领域今天如何从AI中受益？


## 弱人工智能 vs. 强人工智能

弱人工智能 | 强人工智能
---------------------------------------|-------------------------------------
弱AI指的是为特定任务或一小组任务设计和训练的AI系统。|强AI，或称为人工通用智能（AGI），指具有人类水平智能和理解能力的AI系统。
这些AI系统并不具备普遍智能；它们在执行预定义任务方面表现卓越，但缺乏真正的理解力或意识。|这些AI系统具备执行人类能够完成的任何智力任务的能力，能够适应不同的领域，并拥有一种意识或自我意识的形式。
弱AI的例子包括像Siri或Alexa这样的虚拟助理，流媒体服务使用的推荐算法，以及为特定客户服务任务设计的聊天机器人。|实现强AI是AI研究的长期目标，需要开发能够推理、学习、理解和适应广泛任务和情境的AI系统。
弱AI高度专业化，不具备人类般的认知能力或超出其狭窄领域的一般问题解决能力。|强AI目前仍是一个理论概念，尚无AI系统达到这种普遍智能的水平


更多信息参见 **[通用人工智能](https://en.wikipedia.org/wiki/Artificial_general_intelligence)** (AGI).

## 智能的定义和图灵测试

在处理 **[智能](https://en.wikipedia.org/wiki/Intelligence)** 这个术语时遇到的问题之一是，没有一个明确的定义。有人可能会说智能与 **抽象思维** 或 **自我意识** 有关，但我们无法准确定义它。

![猫的照片](../images/photo-cat.jpg)

> [照片](https://unsplash.com/photos/75715CVEJhI)由[Amber Kipp](https://unsplash.com/@sadmax)在Unsplash上发布

为了看到*智能*这个术语的含糊性，试着回答一个问题：“猫智能吗？”。不同的人对这个问题可能会有不同的答案，因为没有一个普遍接受的测试来证明这个断言是真是假。如果你认为有——试着让你的猫接受一个智商测试……

✅ 花一分钟时间思考你是如何定义智能的。一个能解迷宫并获得食物的乌鸦智能吗？一个孩子智能吗？

---

在讨论AGI时，我们需要有某种方法来判断我们是否创造了一个真正智能的系统。[艾伦·图灵](https://en.wikipedia.org/wiki/Alan_Turing) 提出了一种称为 **[图灵测试](https://en.wikipedia.org/wiki/Turing_test)** 的方法，它也像智能的定义一样。这个测试将给定的系统与一些固有的智能实体——一个真实的人类相比较，而且因为任何自动比较都可能被计算机程序绕过，我们使用一个人类审问者。因此，如果一个人类无法在基于文本的对话中区分出真人和计算机系统——该系统就被认为是智能的。

> 一个名为 [Eugene Goostman](https://en.wikipedia.org/wiki/Eugene_Goostman) 的聊天机器人，2014年在圣彼得堡开发，通过使用一个聪明的人格把戏几乎通过了图灵测试。它一开始就宣称自己是一个13岁的乌克兰男孩，这可以解释知识的缺失和文本中的一些不一致之处。在5分钟的对话后，这个机器人说服了30%的评委它是人类，这是图灵认为机器到2000年就能通过的一个标准。然而，我们应该理解，这并不表明我们创造了一个智能系统，或者计算机系统欺骗了人类审问者——系统没有愚弄人类，而是机器人的创造者做到了！

✅ 你有没有被聊天机器人愚弄过，以为你正在与人交谈？它是如何说服你的？


## 人工智能的不同方法

如果我们想让计算机像人类一样行为，我们需要以某种方式在计算机内部建模我们的思维方式。因此，我们需要尝试理解是什么让人类变得智能。

> 为了能够将智能编程到机器中，我们需要理解我们自己做决定的过程是如何运作的。如果你做一点自我反省，你会意识到有些过程是在潜意识中发生的——例如，我们可以在不思考的情况下区分猫和狗——而其他一些则涉及推理。

对这个问题有两种可能的方法：

自顶向下方法（符号推理） | 自底向上方法（神经网络）
----------------------|----------------------
自顶向下方法模拟人解决问题时的推理方式。它涉及从人类中提取**知识**，并将其表示为计算机可读的形式。我们还需要开发一种在计算机内部模拟**推理**的方法。 | 自底向上方法模拟人脑的结构，由称为**神经元**的大量简单单元组成。每个神经元像其输入的加权平均值一样运作，我们可以通过提供**训练数据**来训练神经网络解决有用的问题。

实现智能还有一些其他可能的方法：

* **涌现**、**协同**或**多智能体方法**是基于这样一个事实，即复杂的智能行为可以通过大量简单智能体的相互作用获得。根据[进化控制论](https://en.wikipedia.org/wiki/Global_brain#Evolutionary_cybernetics)，智能可以从更简单的、反应性的行为中在*超系统转换*的过程中**涌现**。

* **进化方法**或**遗传算法**是一种基于进化原理的优化过程。

我们将在课程后面考虑这些方法，但现在我们将专注于两个主要方向：自顶向下和自底向上。

### 自顶向下方法

在**自顶向下方法**中，我们尝试模拟我们的推理过程。因为我们可以在推理时跟随我们的思维，我们可以尝试将这一过程形式化并将其编程到计算机中。这称为**符号推理**。

人们往往在头脑中有一些规则指导他们的决策过程。例如，当医生诊断病人时，他或她可能会意识到一个人发烧了，因此体内可能发生了一些炎症。通过将一大套规则应用于特定问题，医生可能能够得出最终诊断。

这种方法在很大程度上依赖于**知识表示**和**推理**。从人类专家那里提取知识可能是最困难的部分，因为在许多情况下，医生可能并不确切知道他或她为什么会得出特定的诊断。有时解决方案就这样突然出现在他或她的脑海中，无需明确思考。一些任务，如从照片中确定一个人的年龄，根本无法归结为操纵知识。

### 自底向上方法

另一种方法，我们可以尝试模拟大脑内最简单的元素——神经元。我们可以在计算机内构建一个所谓的**人工神经网络**，然后尝试通过给它示例来教它解决问题。这个过程类似于新生儿通过观察其周围环境来学习的方式。

✅ 做一点关于婴儿如何学习的研究。婴儿大脑的基本元素是什么？


>  适合初学者的机器学习|关于机器学习？
> --------------|-----------
>  ![机器学习初学者](../images/ml-for-beginners.png)|基于计算机通过一些数据学习来解决问题的人工智能部分称为**机器学习**。在本课程中我们不会考虑传统的机器学习 - 我们将您引向一个单独的[机器学习初学者](http://aka.ms/ml-beginners)课程。

## 人工智能的简史

人工智能作为一个领域始于二十世纪中叶。最初，符号推理是一种流行的方法，它带来了许多重要的成功，例如专家系统——能够在一些有限的问题领域内充当专家的计算机程序。然而，很快就变得明显，这种方法不具备很好的扩展性。从专家那里提取知识，将其表示在计算机中，以及保持那个知识库的准确性，事实证明是一个非常复杂的任务，并且在许多情况下成本过高而不切实际。这导致了1970年代所谓的[AI寒冬](https://en.wikipedia.org/wiki/AI_winter)。

<img alt="人工智能简史" src="../images/history-of-ai.png" width="70%"/>

> 图片由[Dmitry Soshnikov](http://soshnikov.com)提供

随着时间的推移，计算资源变得更便宜，可用的数据量增加，神经网络方法开始在许多领域与人类竞争展现出卓越的性能，例如计算机视觉或语音理解。在过去的十年中，人工智能这个术语主要被用作神经网络的同义词，因为我们听到的大多数AI成功案例都是基于它们的。

我们可以观察到，在创建国际象棋电脑程序时方法是如何变化的：

* 早期的国际象棋程序基于搜索——程序明确尝试估计对手在接下来的几步中可能的移动，并基于几步之内可以达到的最优位置选择一个最优移动。这导致了所谓的[alpha-beta剪枝](https://en.wikipedia.org/wiki/Alpha%E2%80%93beta_pruning)搜索算法的开发。
* 搜索策略在游戏末端工作得很好，那时搜索空间被可能移动的小数量限制。然而，在游戏开始时，搜索空间巨大，通过从人类玩家之间的现有对局中学习，算法可以得到改进。后续实验采用了所谓的[基于案例的推理](https://en.wikipedia.org/wiki/Case-based_reasoning)，其中程序在知识库中寻找与游戏当前位置非常相似的案例。
* 赢得人类玩家的现代程序基于神经网络和[强化学习](https://en.wikipedia.org/wiki/Reinforcement_learning)，这些程序仅通过长时间与自己对战并从自己的错误中学习来学会下棋——很像人类学习下棋时所做的。然而，计算机程序可以在更短的时间内玩更多的游戏，因此可以更快地学习。

✅ 对AI玩过的其他游戏做一点研究。

同样，我们可以看到创建“会说话的程序”（可能通过图灵测试）的方法是如何变化的：

* 此类早期程序，如[Eliza](https://en.wikipedia.org/wiki/ELIZA)，基于非常简单的语法规则和将输入句子重新构造成一个问题。
* 现代助手，如Cortana、Siri或Google Assistant，都是混合系统，使用神经网络将语音转换成文本并识别我们的意图，然后采用一些推理或明确的算法来执行所需的操作。
* 在未来，我们可能期待一个完全基于神经的模型自己处理对话。最近的GPT和[Turing-NLG](https://turing.microsoft.com/)系列神经网络在此展现了巨大的成功。

<img alt="图灵测试的演变" src="../images/turing-test-evol.png" width="70%"/>

> 图片由Dmitry Soshnikov提供，[照片](https://unsplash.com/photos/r8LmVbUKgns)由[Marina Abrosimova](https://unsplash.com/@abrosimova_marina_foto)在Unsplash上发布


## 最近的人工智能研究

近年来神经网络研究的巨大增长始于2010年左右，当时大型公共数据集开始变得可用。一个包含约1400万标注图像的巨大图像集合[ImageNet](https://en.wikipedia.org/wiki/ImageNet)，催生了[ImageNet大规模视觉识别挑战](https://image-net.org/challenges/LSVRC/)。

![ILSVRC准确性](../images/ilsvrc.gif)

> 图片由[Dmitry Soshnikov](http://soshnikov.com)提供

2012年，[卷积神经网络](../4-ComputerVision/07-ConvNets/README.md)首次被用于图像分类，这导致分类错误率显著下降（从几乎30%降至16.4%）。2015年，微软研究院的ResNet架构[达到了人类水平的准确率](https://doi.org/10.1109/ICCV.2015.123)。

从那时起，神经网络在许多任务中展现出非常成功的行为：

---

年份 | 达到人类水平的成就
-----|--------
2015 | [图像分类](https://doi.org/10.1109/ICCV.2015.123)
2016 | [对话式语音识别](https://arxiv.org/abs/1610.05256)
2018 | [自动机器翻译](https://arxiv.org/abs/1803.05567)（中文到英文）
2020 | [图像字幕](https://arxiv.org/abs/2009.13682)

在过去的几年中，我们见证了大型语言模型，如BERT和GPT-3的巨大成功。这主要是因为有大量的通用文本数据可用，这些数据允许我们训练模型来捕捉文本的结构和含义，先在通用文本集合上对它们进行预训练，然后将这些模型专门用于更具体的任务。我们将在本课程后面更多地学习[自然语言处理](../5-NLP/README.md)。


## 🚀 挑战

在互联网上进行一次探索，确定在你看来，人工智能最有效的使用领域是什么。是在地图应用程序中，还是某种语音转文本服务，或是视频游戏？研究这个系统是如何构建的。

## [课后测验](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/201)

## 复习与自学

通过阅读[这节课](https://github.com/microsoft/ML-For-Beginners/tree/main/1-Introduction/2-history-of-ML)来回顾AI和ML的历史。从该课程或本课程顶部的速写笔记中取一个元素，更深入地研究它，以理解影响其发展的文化背景。

**作业**：[游戏制作大赛](assignment.md)
